{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c64e36e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region: us-east-1\n",
      "Role: arn:aws:iam::152587855666:role/LabRole\n",
      "Default Bucket: sagemaker-us-east-1-152587855666\n",
      "Loading splits from s3://sagemaker-us-east-1-152587855666/datalake/olist/splits/order_level/...\n",
      "Data loaded successfully.\n",
      "Train shape: (39469, 23)\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sagemaker import image_uris\n",
    "import awswrangler as wr\n",
    "\n",
    "# --- Lightweight Setup (Optimized) ---\n",
    "# Replaces time-consuming %run ./01_Data_Preparation.ipynb\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "sm_sess = sagemaker.Session()\n",
    "bucket = sm_sess.default_bucket()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "print(f\"Region: {region}\")\n",
    "print(f\"Role: {role}\")\n",
    "print(f\"Default Bucket: {bucket}\")\n",
    "\n",
    "# --- Load Dataframes from S3 ---\n",
    "# Restores variables expected by downstream cells (previously created by 01)\n",
    "SPLITS_PREFIX = f\"s3://{bucket}/datalake/olist/splits/order_level/\"\n",
    "\n",
    "print(f\"Loading splits from {SPLITS_PREFIX}...\")\n",
    "df_train = wr.s3.read_parquet(path=SPLITS_PREFIX + \"train/\")\n",
    "df_val   = wr.s3.read_parquet(path=SPLITS_PREFIX + \"val/\")\n",
    "df_test  = wr.s3.read_parquet(path=SPLITS_PREFIX + \"test/\")\n",
    "\n",
    "print(\"Data loaded successfully.\")\n",
    "print(\"Train shape:\", df_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "deded73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region: us-east-1\n",
      "Role  : arn:aws:iam::152587855666:role/LabRole\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    ")\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "# Session / region / role\n",
    "sm_sess = sagemaker.Session()\n",
    "region = sm_sess.boto_region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(\"Region:\", region)\n",
    "print(\"Role  :\", role)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "066ded47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (39469, 23)\n",
      "Test  shape: (9867, 23)\n",
      "Val   shape: (9867, 23)\n",
      "Label prevalence (train): 0.7717\n"
     ]
    }
   ],
   "source": [
    "# Check: make sure that these exist from Data_Preparation\n",
    "assert \"df_train\" in globals(), \"df_train not found. Ensure 01_Data_Preparation.ipynb ran successfully.\"\n",
    "assert \"df_test\" in globals(), \"df_test not found. Ensure 01_Data_Preparation.ipynb ran successfully.\"\n",
    "assert \"df_val\" in globals(), \"df_val not found. Ensure 01_Data_Preparation.ipynb ran successfully.\"\n",
    "\n",
    "label_col = \"label_satisfied\"\n",
    "for _df, _name in [(df_train,\"df_train\"), (df_test,\"df_test\"), (df_val,\"df_val\")]:\n",
    "    assert label_col in _df.columns, f\"{label_col} missing from {_name}\"\n",
    "\n",
    "print(\"Train shape:\", df_train.shape)\n",
    "print(\"Test  shape:\", df_test.shape)\n",
    "print(\"Val   shape:\", df_val.shape)\n",
    "print(\"Label prevalence (train):\", df_train[label_col].mean().round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "98e6a393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features: ['total_items', 'total_price', 'total_freight', 'payment_value_sum', 'payment_installments_max', 'delivery_time_days', 'estimated_time_days', 'delivered_late']\n",
      "Categorical features: ['customer_state', 'payment_types']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_items</th>\n",
       "      <th>total_price</th>\n",
       "      <th>total_freight</th>\n",
       "      <th>payment_value_sum</th>\n",
       "      <th>payment_installments_max</th>\n",
       "      <th>delivery_time_days</th>\n",
       "      <th>estimated_time_days</th>\n",
       "      <th>delivered_late</th>\n",
       "      <th>customer_state</th>\n",
       "      <th>payment_types</th>\n",
       "      <th>label_satisfied</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>72.89</td>\n",
       "      <td>63.34</td>\n",
       "      <td>136.23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.206227</td>\n",
       "      <td>45.114363</td>\n",
       "      <td>0</td>\n",
       "      <td>RR</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>59.50</td>\n",
       "      <td>15.56</td>\n",
       "      <td>75.06</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.206227</td>\n",
       "      <td>52.989190</td>\n",
       "      <td>0</td>\n",
       "      <td>RS</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>86.90</td>\n",
       "      <td>17.16</td>\n",
       "      <td>40.95</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.206227</td>\n",
       "      <td>16.358113</td>\n",
       "      <td>0</td>\n",
       "      <td>SP</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>134.97</td>\n",
       "      <td>8.49</td>\n",
       "      <td>105.28</td>\n",
       "      <td>2.0</td>\n",
       "      <td>54.813194</td>\n",
       "      <td>18.488449</td>\n",
       "      <td>1</td>\n",
       "      <td>SP</td>\n",
       "      <td>UNK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>9.34</td>\n",
       "      <td>109.34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.206227</td>\n",
       "      <td>22.077870</td>\n",
       "      <td>0</td>\n",
       "      <td>SP</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_items  total_price  total_freight  payment_value_sum  \\\n",
       "0          2.0        72.89          63.34             136.23   \n",
       "1          1.0        59.50          15.56              75.06   \n",
       "2          1.0        86.90          17.16              40.95   \n",
       "3          3.0       134.97           8.49             105.28   \n",
       "4          1.0       100.00           9.34             109.34   \n",
       "\n",
       "   payment_installments_max  delivery_time_days  estimated_time_days  \\\n",
       "0                       1.0           10.206227            45.114363   \n",
       "1                       3.0           10.206227            52.989190   \n",
       "2                       2.0           10.206227            16.358113   \n",
       "3                       2.0           54.813194            18.488449   \n",
       "4                       1.0           10.206227            22.077870   \n",
       "\n",
       "   delivered_late customer_state payment_types  label_satisfied  \n",
       "0               0             RR   credit_card                0  \n",
       "1               0             RS   credit_card                0  \n",
       "2               0             SP   credit_card                0  \n",
       "3               1             SP           UNK                0  \n",
       "4               0             SP   credit_card                0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature configuration \n",
    "num_features = [\n",
    "    \"total_items\",\n",
    "    \"total_price\",\n",
    "    \"total_freight\",\n",
    "    \"payment_value_sum\",\n",
    "    \"payment_installments_max\",\n",
    "    \"delivery_time_days\",\n",
    "    \"estimated_time_days\",\n",
    "    \"delivered_late\",\n",
    "]\n",
    "cat_features = [\"customer_state\", \"payment_types\"]\n",
    "\n",
    "# Keep only existing columns \n",
    "num_features = [c for c in num_features if c in df_train.columns]\n",
    "cat_features = [c for c in cat_features if c in df_train.columns]\n",
    "\n",
    "print(\"Numeric features:\", num_features)\n",
    "print(\"Categorical features:\", cat_features)\n",
    "\n",
    "def make_model_frame(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    cols = num_features + cat_features + [label_col]\n",
    "    out = df[cols].copy()\n",
    "    # Ensure types\n",
    "    for c in num_features:\n",
    "        out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n",
    "    out[num_features] = out[num_features].fillna(out[num_features].median(numeric_only=True))\n",
    "    for c in cat_features:\n",
    "        out[c] = out[c].fillna(\"UNK\").astype(str)\n",
    "    out[label_col] = out[label_col].astype(int)\n",
    "    return out\n",
    "\n",
    "train_df = make_model_frame(df_train)\n",
    "test_df  = make_model_frame(df_test)\n",
    "val_df   = make_model_frame(df_val)\n",
    "\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9d9b4dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark A — DummyClassifier: {'accuracy': 0.7559541907367995, 'precision': 0.7559541907367995, 'recall': 1.0, 'f1': 0.8610181230520605}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "X_train = train_df.drop(columns=[label_col])\n",
    "y_train = train_df[label_col].values\n",
    "\n",
    "X_test = test_df.drop(columns=[label_col])\n",
    "y_test = test_df[label_col].values\n",
    "\n",
    "# Benchmark A: majority-class baseline\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit(X_train, y_train)\n",
    "pred_dummy = dummy.predict(X_test)\n",
    "\n",
    "def classification_metrics(y_true, y_pred, y_score=None):\n",
    "    out = {\n",
    "        \"accuracy\": float(accuracy_score(y_true, y_pred)),\n",
    "        \"precision\": float(precision_score(y_true, y_pred, zero_division=0)),\n",
    "        \"recall\": float(recall_score(y_true, y_pred, zero_division=0)),\n",
    "        \"f1\": float(f1_score(y_true, y_pred, zero_division=0)),\n",
    "    }\n",
    "    if y_score is not None:\n",
    "        try:\n",
    "            out[\"roc_auc\"] = float(roc_auc_score(y_true, y_score))\n",
    "        except Exception:\n",
    "            pass\n",
    "    return out\n",
    "\n",
    "metrics_dummy = classification_metrics(y_test, pred_dummy)\n",
    "print(\"Benchmark A — DummyClassifier:\", metrics_dummy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4a33ff44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmark B — Tiny LogisticRegression: {'accuracy': 0.7876760920239181, 'precision': 0.7911419887103778, 'recall': 0.9770746748893954, 'f1': 0.8743326735048887, 'roc_auc': 0.639013567635967}\n"
     ]
    }
   ],
   "source": [
    "# Benchmark B: logistic regression on features\n",
    "# delivered_late + delivery_time_days + total_price\n",
    "tiny_feats = [c for c in [\"delivered_late\", \"delivery_time_days\", \"total_price\"] if c in X_train.columns]\n",
    "assert len(tiny_feats) >= 1, \"No tiny benchmark features found; adjust tiny_feats list.\"\n",
    "\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", \"passthrough\", tiny_feats),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "bench_lr = Pipeline(steps=[\n",
    "    (\"pre\", pre),\n",
    "    (\"clf\", LogisticRegression(max_iter=200, n_jobs=None)),\n",
    "])\n",
    "bench_lr.fit(X_train, y_train)\n",
    "\n",
    "pred_lr = bench_lr.predict(X_test)\n",
    "proba_lr = None\n",
    "if hasattr(bench_lr.named_steps[\"clf\"], \"predict_proba\"):\n",
    "    proba_lr = bench_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "metrics_lr = classification_metrics(y_test, pred_lr, y_score=proba_lr)\n",
    "print(\"Benchmark B — Tiny LogisticRegression:\", metrics_lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9b421af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39469, 42), (9867, 42), (9867, 42))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Full preprocessing for model training \n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", \"passthrough\", num_features),\n",
    "        (\"cat\", ohe, cat_features),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "# Fit on train only\n",
    "X_train_mat = preprocess.fit_transform(X_train)\n",
    "X_val_mat   = preprocess.transform(val_df.drop(columns=[label_col]))\n",
    "X_test_mat  = preprocess.transform(X_test)\n",
    "\n",
    "y_val = val_df[label_col].values\n",
    "\n",
    "# Helper to create XGBoost CSV \n",
    "def to_xgb_csv(X_mat, y_vec) -> pd.DataFrame:\n",
    "    y_vec = np.asarray(y_vec).reshape(-1, 1)\n",
    "    arr = np.hstack([y_vec, X_mat])\n",
    "    return pd.DataFrame(arr)\n",
    "\n",
    "train_xgb = to_xgb_csv(X_train_mat, y_train)\n",
    "val_xgb   = to_xgb_csv(X_val_mat, y_val)\n",
    "test_xgb  = to_xgb_csv(X_test_mat, y_test)\n",
    "\n",
    "train_xgb.shape, val_xgb.shape, test_xgb.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d7b92afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded dataset prefixes:\n",
      "  train: s3://sagemaker-us-east-1-152587855666/modeling/xgb-baseline/train/\n",
      "  val  : s3://sagemaker-us-east-1-152587855666/modeling/xgb-baseline/val/\n",
      "  test : s3://sagemaker-us-east-1-152587855666/modeling/xgb-baseline/test/\n"
     ]
    }
   ],
   "source": [
    "import awswrangler as wr\n",
    "\n",
    "if \"DATALAKE_BUCKET\" in globals() and isinstance(DATALAKE_BUCKET, str) and len(DATALAKE_BUCKET) > 0:\n",
    "    bucket = DATALAKE_BUCKET\n",
    "else:\n",
    "    bucket = sm_sess.default_bucket()\n",
    "\n",
    "base_prefix = f\"s3://{bucket}/modeling/xgb-baseline/\"\n",
    "\n",
    "train_prefix = base_prefix + \"train/\"\n",
    "val_prefix   = base_prefix + \"val/\"\n",
    "test_prefix  = base_prefix + \"test/\"\n",
    "\n",
    "# Writes one or more CSV files under each prefix, overwriting existing data\n",
    "wr.s3.to_csv(train_xgb, path=train_prefix, index=False, header=False, dataset=True, mode=\"overwrite\")\n",
    "wr.s3.to_csv(val_xgb,   path=val_prefix,   index=False, header=False, dataset=True, mode=\"overwrite\")\n",
    "wr.s3.to_csv(test_xgb,  path=test_prefix,  index=False, header=False, dataset=True, mode=\"overwrite\")\n",
    "\n",
    "print(\"Uploaded dataset prefixes:\")\n",
    "print(\"  train:\", train_prefix)\n",
    "print(\"  val  :\", val_prefix)\n",
    "print(\"  test :\", test_prefix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fix_missing_defs",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "WARNING:sagemaker.estimator:No finished training job found associated with this estimator. Please make sure this estimator is only used for building workflow config\n"
     ]
    }
   ],
   "source": [
    "# Define paths used in training/validation\n",
    "s3_train = train_prefix\n",
    "s3_val   = val_prefix\n",
    "s3_test  = test_prefix\n",
    "\n",
    "output_path = f\"s3://{bucket}/modeling/output\"\n",
    "transform_output = base_prefix + \"transform-output/\"\n",
    "\n",
    "# Image URI\n",
    "xgb_image = image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=\"1.5-1\"\n",
    ")\n",
    "\n",
    "# Estimator Definition\n",
    "xgb = sagemaker.estimator.Estimator(\n",
    "    image_uri=xgb_image,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    output_path=output_path,\n",
    "    sagemaker_session=sm_sess\n",
    ")\n",
    "\n",
    "xgb.set_hyperparameters(\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.8,\n",
    "    objective=\"binary:logistic\",\n",
    "    num_round=50\n",
    ")\n",
    "\n",
    "# Transformer Definition\n",
    "transformer = xgb.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    output_path=transform_output\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0e70aa4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-xgboost-2026-02-02-04-35-18-390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing training artifacts in s3://sagemaker-us-east-1-152587855666/modeling/output. Skipping Training to save cost.\n",
      "   Using latest model artifact: s3://sagemaker-us-east-1-152587855666/modeling/output/sagemaker-xgboost-2026-02-02-04-00-02-225/output/model.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: sagemaker-xgboost-2026-02-02-04-35-19-137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-created transformer object linked to current model.\n"
     ]
    }
   ],
   "source": [
    "train_input = TrainingInput(s3_data=os.path.dirname(s3_train) + \"/\", content_type=\"text/csv\")\n",
    "val_input   = TrainingInput(s3_data=os.path.dirname(s3_val) + \"/\",   content_type=\"text/csv\")\n",
    "\n",
    "# --- COST SAFETY CHECK ---\n",
    "import boto3\n",
    "import time\n",
    "from urllib.parse import urlparse\n",
    "from sagemaker.model import Model\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "def check_s3_prefix_has_contents(bucket_name, prefix):\n",
    "    resp = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)\n",
    "    return resp.get('KeyCount', 0) > 0\n",
    "\n",
    "# Parse the output path defined in previous cells\n",
    "p = urlparse(output_path)\n",
    "out_bucket = p.netloc\n",
    "out_key_prefix = p.path.lstrip('/')\n",
    "\n",
    "if check_s3_prefix_has_contents(out_bucket, out_key_prefix):\n",
    "    print(f'Found existing training artifacts in {output_path}. Skipping Training to save cost.')\n",
    "    # Find latest model artifact\n",
    "    resp = s3_client.list_objects_v2(Bucket=out_bucket, Prefix=out_key_prefix)\n",
    "    contents = sorted(resp.get('Contents', []), key=lambda x: x['LastModified'], reverse=True)\n",
    "    model_uri = None\n",
    "    for c in contents:\n",
    "        if c['Key'].endswith('/output/model.tar.gz'):\n",
    "            model_uri = f's3://{out_bucket}/{c[\"Key\"]}'\n",
    "            break\n",
    "    if model_uri:\n",
    "        print(f'   Using latest model artifact: {model_uri}')\n",
    "        # Recreate Estimator/Model so next cells work\n",
    "        xgb_model = Model(\n",
    "            image_uri=xgb_image,\n",
    "            model_data=model_uri,\n",
    "            role=role,\n",
    "            sagemaker_session=sm_sess\n",
    "        )\n",
    "        xgb_model.create()\n",
    "        # Swap xgb (Estimator) to xgb_model (Model) for transformer usage\n",
    "        xgb = xgb_model\n",
    "    else:\n",
    "        print('   Output dir exists but no model found. Retraining...')\n",
    "        xgb.fit({'train': train_input, 'validation': val_input}, logs=False)\n",
    "else:\n",
    "    print('No existing training artifacts found. Starting Training...')\n",
    "    xgb.fit({'train': train_input, 'validation': val_input}, logs=False)\n",
    "\n",
    "# --- FIX: Re-instantiate Transformer ---\n",
    "# Ensure transformer uses the correct model (whether trained now or loaded from S3)\n",
    "transformer = xgb.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    output_path=transform_output\n",
    ")\n",
    "print(\"Re-created transformer object linked to current model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4c1829fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: sagemaker-xgboost-2026-02-02-04-35-20-834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform input prefix (features): s3://sagemaker-us-east-1-152587855666/athena-results/test/features_only/\n",
      "Transform output path            : s3://sagemaker-us-east-1-152587855666/modeling/xgb-baseline/transform-output/\n",
      "No existing transform output. Starting Batch Transform...\n",
      "..........................\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:42:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:42:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:42:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2026-02-02 04:39:42 +0000] [19] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2026-02-02 04:39:42 +0000] [19] [INFO] Listening at: unix:/tmp/gunicorn.sock (19)\u001b[0m\n",
      "\u001b[34m[2026-02-02 04:39:42 +0000] [19] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/os.py:1023: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  return io.open(fd, *args, **kwargs)\u001b[0m\n",
      "\u001b[34m[2026-02-02 04:39:42 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[34m[2026-02-02 04:39:42 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m[2026-02-02 04:39:42 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[34m[2026-02-02 04:39:42 +0000] [28] [INFO] Booting worker with pid: 28\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:45:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:45:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:45:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:45:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:45:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:45:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:45:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:45:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:45:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:45:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:45:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:45:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:47:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [02/Feb/2026:04:39:47 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:47:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [02/Feb/2026:04:39:47 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\n",
      "\u001b[34m[2026-02-02:04:39:48:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:48:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [02/Feb/2026:04:39:48 +0000] \"POST /invocations HTTP/1.1\" 200 186889 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2026-02-02:04:39:48:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2026-02-02:04:39:48:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.8/site-packages/xgboost/core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [02/Feb/2026:04:39:48 +0000] \"POST /invocations HTTP/1.1\" 200 186889 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2026-02-02T04:39:47.886:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:42:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:42:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:42:INFO] nginx config: \u001b[0m\n",
      "\u001b[34mworker_processes auto;\u001b[0m\n",
      "\u001b[34mdaemon off;\u001b[0m\n",
      "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[34mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\u001b[0m\n",
      "\u001b[35m[2026-02-02:04:39:42:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2026-02-02:04:39:42:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2026-02-02:04:39:42:INFO] nginx config: \u001b[0m\n",
      "\u001b[35mworker_processes auto;\u001b[0m\n",
      "\u001b[35mdaemon off;\u001b[0m\n",
      "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
      "\u001b[35merror_log  /dev/stderr;\u001b[0m\n",
      "\u001b[35mworker_rlimit_nofile 4096;\u001b[0m\n",
      "\u001b[35mevents {\n",
      "  worker_connections 2048;\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[34mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m[2026-02-02 04:39:42 +0000] [19] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m[2026-02-02 04:39:42 +0000] [19] [INFO] Listening at: unix:/tmp/gunicorn.sock (19)\u001b[0m\n",
      "\u001b[34m[2026-02-02 04:39:42 +0000] [19] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/os.py:1023: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  return io.open(fd, *args, **kwargs)\u001b[0m\n",
      "\u001b[34m[2026-02-02 04:39:42 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[34m[2026-02-02 04:39:42 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[34m[2026-02-02 04:39:42 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[34m[2026-02-02 04:39:42 +0000] [28] [INFO] Booting worker with pid: 28\u001b[0m\n",
      "\u001b[35mhttp {\n",
      "  include /etc/nginx/mime.types;\n",
      "  default_type application/octet-stream;\n",
      "  access_log /dev/stdout combined;\n",
      "  upstream gunicorn {\n",
      "    server unix:/tmp/gunicorn.sock;\n",
      "  }\n",
      "  server {\n",
      "    listen 8080 deferred;\n",
      "    client_max_body_size 0;\n",
      "    keepalive_timeout 3;\n",
      "    location ~ ^/(ping|invocations|execution-parameters) {\n",
      "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "      proxy_set_header Host $http_host;\n",
      "      proxy_redirect off;\n",
      "      proxy_read_timeout 60s;\n",
      "      proxy_pass http://gunicorn;\n",
      "    }\n",
      "    location / {\n",
      "      return 404 \"{}\";\n",
      "    }\n",
      "  }\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35m[2026-02-02 04:39:42 +0000] [19] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[35m[2026-02-02 04:39:42 +0000] [19] [INFO] Listening at: unix:/tmp/gunicorn.sock (19)\u001b[0m\n",
      "\u001b[35m[2026-02-02 04:39:42 +0000] [19] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.8/os.py:1023: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  return io.open(fd, *args, **kwargs)\u001b[0m\n",
      "\u001b[35m[2026-02-02 04:39:42 +0000] [25] [INFO] Booting worker with pid: 25\u001b[0m\n",
      "\u001b[35m[2026-02-02 04:39:42 +0000] [26] [INFO] Booting worker with pid: 26\u001b[0m\n",
      "\u001b[35m[2026-02-02 04:39:42 +0000] [27] [INFO] Booting worker with pid: 27\u001b[0m\n",
      "\u001b[35m[2026-02-02 04:39:42 +0000] [28] [INFO] Booting worker with pid: 28\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:45:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:45:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:45:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:45:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:45:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:45:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\u001b[0m\n",
      "\u001b[35m[2026-02-02:04:39:45:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2026-02-02:04:39:45:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2026-02-02:04:39:45:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2026-02-02:04:39:45:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2026-02-02:04:39:45:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2026-02-02:04:39:45:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:45:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:45:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:45:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:45:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2026-02-02:04:39:45:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2026-02-02:04:39:45:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2026-02-02:04:39:45:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2026-02-02:04:39:45:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:45:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:45:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[35m[2026-02-02:04:39:45:INFO] Loading the model from /opt/ml/model/xgboost-model\u001b[0m\n",
      "\u001b[35m[2026-02-02:04:39:45:INFO] Model objective : binary:logistic\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:47:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [02/Feb/2026:04:39:47 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:47:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [02/Feb/2026:04:39:47 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2026-02-02:04:39:47:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [02/Feb/2026:04:39:47 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2026-02-02:04:39:47:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [02/Feb/2026:04:39:47 +0000] \"GET /execution-parameters HTTP/1.1\" 200 84 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:48:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2026-02-02:04:39:48:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [02/Feb/2026:04:39:48 +0000] \"POST /invocations HTTP/1.1\" 200 186889 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2026-02-02:04:39:48:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m[2026-02-02:04:39:48:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m/miniconda3/lib/python3.8/site-packages/xgboost/core.py:105: UserWarning: ntree_limit is deprecated, use `iteration_range` or model slicing instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [02/Feb/2026:04:39:48 +0000] \"POST /invocations HTTP/1.1\" 200 186889 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[32m2026-02-02T04:39:47.886:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "Batch transform complete.\n"
     ]
    }
   ],
   "source": [
    "# For transform, we provide features only\n",
    "test_features_only = test_xgb.drop(columns=[0])  \n",
    "\n",
    "# Write as a dataset under a prefix \n",
    "test_features_prefix = f\"s3://{bucket}/{prefix}test/features_only/\"\n",
    "\n",
    "wr.s3.to_csv(\n",
    "    test_features_only,\n",
    "    path=test_features_prefix,\n",
    "    index=False,\n",
    "    header=False,\n",
    "    dataset=True,\n",
    "    mode=\"overwrite\",\n",
    ")\n",
    "\n",
    "print(\"Transform input prefix (features):\", test_features_prefix)\n",
    "print(\"Transform output path            :\", transform_output)\n",
    "\n",
    "# --- COST SAFETY CHECK ---\n",
    "t_parse = urlparse(transform_output)\n",
    "t_bucket = t_parse.netloc\n",
    "t_prefix = t_parse.path.lstrip('/')\n",
    "\n",
    "if check_s3_prefix_has_contents(t_bucket, t_prefix):\n",
    "    print(f'Found existing transform output in {transform_output}. Skipping Transform.')\n",
    "else:\n",
    "    print('No existing transform output. Starting Batch Transform...')\n",
    "    transformer.transform(\n",
    "        data=test_features_prefix,\n",
    "        content_type='text/csv',\n",
    "        split_type='Line',\n",
    "    )\n",
    "    transformer.wait()\n",
    "    print('Batch transform complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "09f60821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output objects: ['modeling/xgb-baseline/transform-output/aa93f46d315c4a60bdac2ff001d4f1f9.csv.out']\n",
      "Using output file: modeling/xgb-baseline/transform-output/aa93f46d315c4a60bdac2ff001d4f1f9.csv.out\n",
      "SageMaker XGBoost metrics: {'accuracy': 0.8098712881321577, 'precision': 0.8079426365140651, 'recall': 0.9819010591232069, 'f1': 0.8864681675139191, 'roc_auc': 0.7298518167310201}\n",
      "\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8317    0.2770    0.4156      2408\n",
      "           1     0.8079    0.9819    0.8865      7459\n",
      "\n",
      "    accuracy                         0.8099      9867\n",
      "   macro avg     0.8198    0.6294    0.6510      9867\n",
      "weighted avg     0.8137    0.8099    0.7715      9867\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "# List objects under output prefix to find the output file\n",
    "s3 = boto3.client(\"s3\")\n",
    "# Fix: Use the actual transform output path\n",
    "parsed_out = urlparse(transform_output)\n",
    "out_prefix = parsed_out.path.lstrip('/')\n",
    "\n",
    "resp = s3.list_objects_v2(Bucket=bucket, Prefix=out_prefix)\n",
    "keys = [obj[\"Key\"] for obj in resp.get(\"Contents\", [])]\n",
    "print(\"Output objects:\", keys)\n",
    "\n",
    "out_files = [k for k in keys if k.endswith(\".out\") or k.endswith(\".csv\") or \"test_features\" in k]\n",
    "\n",
    "candidate = None\n",
    "for k in keys:\n",
    "    if k.endswith(\".out\"):\n",
    "        candidate = k\n",
    "        break\n",
    "if candidate is None:\n",
    "    raise RuntimeError(\"Could not find batch transform output .out file. Check S3 output prefix listing above.\")\n",
    "\n",
    "print(\"Using output file:\", candidate)\n",
    "\n",
    "obj = s3.get_object(Bucket=bucket, Key=candidate)\n",
    "raw = obj[\"Body\"].read().decode(\"utf-8\").strip().splitlines()\n",
    "\n",
    "# Each line is a probability \n",
    "y_score = np.array([float(x.strip().split(\",\")[0]) for x in raw])\n",
    "y_pred = (y_score >= 0.5).astype(int)\n",
    "\n",
    "metrics_xgb = classification_metrics(y_test, y_pred, y_score=y_score)\n",
    "\n",
    "print(\"SageMaker XGBoost metrics:\", metrics_xgb)\n",
    "print()\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3a84a50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Benchmark A: Dummy (most_frequent)</td>\n",
       "      <td>0.755954</td>\n",
       "      <td>0.755954</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.861018</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Benchmark B: Tiny LR (delivered_late, delivery...</td>\n",
       "      <td>0.787676</td>\n",
       "      <td>0.791142</td>\n",
       "      <td>0.977075</td>\n",
       "      <td>0.874333</td>\n",
       "      <td>0.639014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SageMaker: XGBoost (batch transform)</td>\n",
       "      <td>0.809871</td>\n",
       "      <td>0.807943</td>\n",
       "      <td>0.981901</td>\n",
       "      <td>0.886468</td>\n",
       "      <td>0.729852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               model  accuracy  precision  \\\n",
       "0                 Benchmark A: Dummy (most_frequent)  0.755954   0.755954   \n",
       "1  Benchmark B: Tiny LR (delivered_late, delivery...  0.787676   0.791142   \n",
       "2               SageMaker: XGBoost (batch transform)  0.809871   0.807943   \n",
       "\n",
       "     recall        f1   roc_auc  \n",
       "0  1.000000  0.861018       NaN  \n",
       "1  0.977075  0.874333  0.639014  \n",
       "2  0.981901  0.886468  0.729852  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Side-by-side comparison\n",
    "compare = pd.DataFrame([\n",
    "    {\"model\": \"Benchmark A: Dummy (most_frequent)\", **metrics_dummy},\n",
    "    {\"model\": f\"Benchmark B: Tiny LR ({', '.join(tiny_feats)})\", **metrics_lr},\n",
    "    {\"model\": \"SageMaker: XGBoost (batch transform)\", **metrics_xgb},\n",
    "])\n",
    "\n",
    "# Reorder columns\n",
    "cols = [\"model\"] + [c for c in [\"accuracy\",\"precision\",\"recall\",\"f1\",\"roc_auc\"] if c in compare.columns]\n",
    "compare = compare[cols]\n",
    "compare\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16599b4-2fa7-47af-b23c-077587555537",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
